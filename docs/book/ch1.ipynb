{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition update_downstream!(Quarton.SizeIntervalAssignment, Any, Any, Any) in module Quarton at /home/adolgert/dev/quarton/src/disbursement.jl:59 overwritten at /home/adolgert/dev/quarton/src/disbursement.jl:71.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition total_work(Quarton.FIFOQueue) in module Quarton at /home/adolgert/dev/quarton/src/queue.jl:36 overwritten at /home/adolgert/dev/quarton/src/queue.jl:76.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using DataStructures\n",
    "using Distributions\n",
    "using Quarton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5167163561993535"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function doubling_arrival_rate(arrival_rate, service_rate)\n",
    "    model = QueueModel()\n",
    "    source = add_queue!(model, InfiniteSourceQueue())\n",
    "    fifo = add_queue!(model, FIFOQueue())\n",
    "    sink = add_queue!(model, SinkQueue())\n",
    "    s1 = add_server!(model, ArrivalServer(arrival_rate))\n",
    "    s2 = add_server!(model, ModifyServer(service_rate))\n",
    "    connect!(model, source, s1, :only)\n",
    "    connect!(model, s1, fifo, :only)\n",
    "    connect!(model, fifo, s2, :only)\n",
    "    connect!(model, s2, sink, :only)\n",
    "    check_model(model)\n",
    "    trajectory = Trajectory(2342334)\n",
    "    start_time = zero(Float64)\n",
    "    activate!(model, trajectory, s1, Work())\n",
    "    when = 0.0\n",
    "    while when < 10000.0\n",
    "        when, which = next(trajectory)\n",
    "        step!(model, trajectory, (when, which))\n",
    "    end\n",
    "    response = sink.retire_total_duration / sink.retire_cnt\n",
    "    return response\n",
    "end\n",
    "doubling_arrival_rate(3.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.002811729249586, 34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simplistic stochastic search. Start with two values and use the slope to\n",
    "determine how much to modify the current guess.\n",
    "\"\"\"\n",
    "function doubling_arrival_rate_find_closest(; slowly=0.1, recent=10)\n",
    "    x = CircularBuffer{Float64}(recent)\n",
    "    y = CircularBuffer{Float64}(recent)\n",
    "    service_rate = 5.0\n",
    "    response = doubling_arrival_rate(6.0, service_rate)\n",
    "    push!(x, service_rate)\n",
    "    push!(y, response)\n",
    "    service_rate = 10.0\n",
    "    response = doubling_arrival_rate(6.0, service_rate)\n",
    "    push!(x, service_rate)\n",
    "    push!(y, response)\n",
    "    desired = 0.5167\n",
    "    slowly = slowly\n",
    "    iteration_cnt = 1\n",
    "    while abs(response - desired) > 0.001 && iteration_cnt < 100\n",
    "        # Do a small linear least squares by hand to get the slope.\n",
    "        X = ones(length(x), 2)\n",
    "        X[:, 2] .= x\n",
    "        β = (X' * X) \\ (X' * y)\n",
    "        service_rate += slowly * (desired - response) / β[2]\n",
    "        response = doubling_arrival_rate(6.0, service_rate)\n",
    "        push!(x, service_rate)\n",
    "        push!(y, response)\n",
    "        iteration_cnt += 1\n",
    "    end\n",
    "    service_rate, iteration_cnt\n",
    "end\n",
    "doubling_arrival_rate_find_closest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design example 2 - Sometimes \"Improvements\" Do Nothing\n",
    "\n",
    "Page 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.5755\n",
       " 0.6535\n",
       " 0.6669\n",
       " 0.6675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function improvements_do_nothing(\n",
    "    service_rate; base_rate=1/3, stopping_time=10000.0\n",
    "    )\n",
    "    model = QueueModel()\n",
    "    fifo1 = add_queue!(model, FIFOQueue())\n",
    "    fifo2 = add_queue!(model, FIFOQueue())\n",
    "    s1 = ModifyServer(service_rate, disbursement=RandomAssignment())\n",
    "    add_server!(model, s1)\n",
    "    s2 = ModifyServer(base_rate, disbursement=RandomAssignment())\n",
    "    add_server!(model, s2)\n",
    "    connect!(model, fifo1, s1, :only)\n",
    "    connect!(model, s1, fifo1, :low)\n",
    "    connect!(model, s1, fifo2, :high)\n",
    "    connect!(model, fifo2, s2, :only)\n",
    "    connect!(model, s2, fifo1, :low)\n",
    "    connect!(model, s2, fifo2, :high)\n",
    "    check_model(model)\n",
    "    trajectory = Trajectory(2342334)\n",
    "    start_time = zero(Float64)\n",
    "    # Need to start some reaction to get it going.\n",
    "    activate!(model, trajectory, s1, Work())\n",
    "    activate!(model, trajectory, s2, Work())\n",
    "    # Question wants 6 tokens, and 2 are already being processed.\n",
    "    for token_idx in 1:2\n",
    "        push!(fifo1, Work(), start_time)\n",
    "        push!(fifo2, Work(), start_time)\n",
    "    end\n",
    "    when = 0.0\n",
    "    process_cnt = 0\n",
    "    while when < stopping_time\n",
    "        when, which = next(trajectory)\n",
    "        if which === nothing\n",
    "            println(\"no event at time $when step $(process_cnt)\")\n",
    "        end\n",
    "        step!(model, trajectory, (when, which))\n",
    "        process_cnt += 1\n",
    "    end\n",
    "    return process_cnt / stopping_time\n",
    "end\n",
    "\n",
    "[improvements_do_nothing(rate) for rate in [1/3, 1/2, 2.0, 10.0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the system had higher multiprogramming level N. Does the answer change? The multiprogramming level is the total number of parallel servers. We will make a bunch of servers and queues and connect the output of every server to the input of every queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6707, 1.1625, 2.103, 4.1144], [0.6675, 1.1357, 2.1129, 4.0858])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function improvements_do_nothing_higher_multiprogramming(\n",
    "    service_rate; base_rate=1/3, stopping_time=10000.0, N=10\n",
    "    )\n",
    "    model = QueueModel()\n",
    "    queues = Vector{FIFOQueue}(undef, N)\n",
    "    for create_queue in 1:N\n",
    "        queues[create_queue] = add_queue!(model, FIFOQueue())\n",
    "    end\n",
    "    servers = Vector{ModifyServer}(undef, N)\n",
    "    servers[1] = ModifyServer(service_rate, disbursement=RandomAssignment())\n",
    "    add_server!(model, servers[1])\n",
    "    for create_server in 2:N\n",
    "        # These are at the base_rate, not the one we speed up.\n",
    "        s2 = ModifyServer(base_rate, disbursement=RandomAssignment())\n",
    "        add_server!(model, s2)\n",
    "        servers[create_server] = s2\n",
    "    end\n",
    "    roles = [gensym() for _ in 1:N]\n",
    "    for s_connect in 1:N\n",
    "        connect!(model, queues[s_connect], servers[s_connect], :only)\n",
    "        for q_connect in 1:N\n",
    "            connect!(model, servers[s_connect], queues[q_connect], roles[q_connect])\n",
    "        end\n",
    "    end\n",
    "    check_model(model)\n",
    "    trajectory = Trajectory(2342334)\n",
    "    start_time = zero(Float64)\n",
    "    # Need to start some reaction to get it going.\n",
    "    for start_server in 1:N\n",
    "        activate!(model, trajectory, servers[start_server], Work())\n",
    "    end\n",
    "    # Question wants 6 tokens, and 2 are already being processed.\n",
    "    for fill_queue in 1:N\n",
    "        for token_idx in 1:2\n",
    "            push!(queues[fill_queue], Work(), start_time)\n",
    "        end\n",
    "    end\n",
    "    when = 0.0\n",
    "    process_cnt = 0\n",
    "    while when < stopping_time\n",
    "        when, which = next(trajectory)\n",
    "        if which === nothing\n",
    "            println(\"no event at time $when step $(process_cnt)\")\n",
    "        end\n",
    "        step!(model, trajectory, (when, which))\n",
    "        process_cnt += 1\n",
    "    end\n",
    "    return process_cnt / stopping_time\n",
    "end\n",
    "a = [improvements_do_nothing_higher_multiprogramming(6.0, N=n) for n in [2, 4, 8, 16]]\n",
    "b = [improvements_do_nothing_higher_multiprogramming(10.0, N=n) for n in [2, 4, 8, 16]]\n",
    "(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Example 3 - One Machine or Many?\n",
    "\n",
    "Page 7. You are given a choice between one fast CPU of speed $s$ or $n$ slow CPUs each of speed $s/n$. Your goal is to minimize mean response time. To start, assume that jobs are non-preemptible, which means they must run to completion without interruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 15.514343546710185\n",
       " 23.980658038533136\n",
       " 39.70529089955526\n",
       " 84.09416620939764"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert from [0,1] to [20,1].\n",
    "function gamma_k(job_variability)\n",
    "    kmax = 20\n",
    "    kmin = 1.001\n",
    "    return 1.0 + (kmin - kmax) * (job_variability - 1.0)\n",
    "end\n",
    "\n",
    "function one_machine_or_many_single(arrival_rate, service_rate, job_variability)\n",
    "    # Represent job variability by using a Gamma distribution for token workload.\n",
    "    # Mean of a distribution is kθ. Generally want 1 < k < 20. Keep kθ=1.\n",
    "    # Small k = more spread.\n",
    "    k = gamma_k(job_variability)\n",
    "    work_dist = (when, rng) -> Work(rand(rng, Gamma(k, 1/k)), when)\n",
    "    model = QueueModel()\n",
    "    source = add_queue!(model, InfiniteSourceQueue(work_dist))\n",
    "    fifo = add_queue!(model, FIFOQueue())\n",
    "    sink = add_queue!(model, SinkQueue())\n",
    "    s1 = add_server!(model, ArrivalServer(arrival_rate))\n",
    "    s2 = add_server!(model, ModifyServer(service_rate))\n",
    "    connect!(model, source, s1, :only)\n",
    "    connect!(model, s1, fifo, :only)\n",
    "    connect!(model, fifo, s2, :only)\n",
    "    connect!(model, s2, sink, :only)\n",
    "    check_model(model)\n",
    "    trajectory = Trajectory(2342334)\n",
    "    start_time = zero(Float64)\n",
    "    activate!(model, trajectory, s1, Work())\n",
    "    when = 0.0\n",
    "    while when < 10000.0\n",
    "        when, which = next(trajectory)\n",
    "        step!(model, trajectory, (when, which))\n",
    "    end\n",
    "    response = sink.retire_total_duration / sink.retire_cnt\n",
    "    return response\n",
    "end\n",
    "[one_machine_or_many_single(4.0, 4.0, variability)\n",
    " for variability in [0.0, 0.5, 0.7, 0.99]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the single server with rate 4 and split it into 10 servers with rate 4/10. For workloads with low variability, it's better to have the faster server (15s single vs 45s multiple). For workloads with high variability, it's better to have many slower servers (84s single vs 27s multiple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 45.98084383697046\n",
       " 64.19296764223655\n",
       " 96.82479025436999\n",
       " 27.451872678339"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function one_machine_or_many_many(\n",
    "    arrival_rate, service_rate, job_variability, N=10\n",
    "    )\n",
    "    k = gamma_k(job_variability)\n",
    "    work_dist = (when, rng) -> Work(rand(rng, Gamma(k, 1/k)), when)\n",
    "    model = QueueModel()\n",
    "    source = add_queue!(model, InfiniteSourceQueue(work_dist))\n",
    "    fifo = add_queue!(model, FIFOQueue())\n",
    "    sink = add_queue!(model, SinkQueue())\n",
    "    s1 = add_server!(model, ArrivalServer(arrival_rate))\n",
    "    servers = Vector{ModifyServer}(undef, N)\n",
    "    for s_create_idx in 1:N\n",
    "        s2 = add_server!(model, ModifyServer(service_rate))\n",
    "        servers[s_create_idx] = s2\n",
    "    end\n",
    "    connect!(model, source, s1, :only)\n",
    "    connect!(model, s1, fifo, :only)\n",
    "    for s_connect_idx in 1:N\n",
    "        connect!(model, fifo, servers[s_connect_idx], gensym())\n",
    "        connect!(model, servers[s_connect_idx], sink, :only)\n",
    "    end\n",
    "    check_model(model)\n",
    "    trajectory = Trajectory(2342334)\n",
    "    start_time = zero(Float64)\n",
    "    activate!(model, trajectory, s1, Work())\n",
    "    when = 0.0\n",
    "    while when < 10000.0\n",
    "        when, which = next(trajectory)\n",
    "        step!(model, trajectory, (when, which))\n",
    "    end\n",
    "    response = sink.retire_total_duration / sink.retire_cnt\n",
    "    return response\n",
    "end\n",
    "N = 10\n",
    "[one_machine_or_many_many(4.0, 4.0 / N, variability, N)\n",
    " for variability in [0.0, 0.5, 0.7, 0.99]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Example 4 - Task Assignment in a server farm\n",
    "\n",
    "Page 9, we have arrivals going to a dispatcher, or load balancer, which directs jobs to N hosts. The question is which method of dispatch works best, among\n",
    "\n",
    " * Random\n",
    " * Round-robin\n",
    " * Shortest-queue - Check the number of jobs in each destination queue\n",
    " * Size-Interval-Task-Assignment - Designate short, medium, or long jobs to sets of servers by type.\n",
    " * Least-Work-Left - Each queue totals the workload in all of its jobs, and choose the one with the least total.\n",
    " * Central-queue - All servers pull from one central set of jobs and get the first one.\n",
    "\n",
    "Note that there is some confusion here in the text, which is OK because it's at the beginning. There are two questions, not one, which are who gets a job and which job they get.\n",
    "\n",
    "Quarton has Assignment classes that represent these choices above. We could try various ones. This isn't the right time to explore all of the options and analyze them, so let's just show one popular choice, like least-work-left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4503.310655770496"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function task_assignment_server_farm(\n",
    "    arrival_rate, service_rate, job_variability, N=10\n",
    "    )\n",
    "    k = gamma_k(job_variability)\n",
    "    work_dist = (when, rng) -> Work(rand(rng, Gamma(k, 1/k)), when)\n",
    "    model = QueueModel()\n",
    "    source = add_queue!(model, InfiniteSourceQueue(work_dist))\n",
    "    fifo = add_queue!(model, FIFOQueue())\n",
    "    sink = add_queue!(model, SinkQueue())\n",
    "    assign_strategy = LeastWorkLeft()\n",
    "    s1 = add_server!(model, ArrivalServer(arrival_rate, disbursement=assign_strategy))\n",
    "    servers = Vector{ModifyServer}(undef, N)\n",
    "    for s_create_idx in 1:N\n",
    "        s2 = add_server!(model, ModifyServer(service_rate))\n",
    "        servers[s_create_idx] = s2\n",
    "    end\n",
    "    connect!(model, source, s1, :only)\n",
    "    connect!(model, s1, fifo, :only)\n",
    "    for s_connect_idx in 1:N\n",
    "        connect!(model, fifo, servers[s_connect_idx], gensym())\n",
    "        connect!(model, servers[s_connect_idx], sink, :only)\n",
    "    end\n",
    "    check_model(model)\n",
    "    trajectory = Trajectory(2342334)\n",
    "    start_time = zero(Float64)\n",
    "    activate!(model, trajectory, s1, Work())\n",
    "    when = 0.0\n",
    "    while when < 10000.0\n",
    "        when, which = next(trajectory)\n",
    "        step!(model, trajectory, (when, which))\n",
    "    end\n",
    "    response = sink.retire_total_duration / sink.retire_cnt\n",
    "    return response\n",
    "end\n",
    "task_assignment_server_farm(100.0, 1.0, 0.2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Example 5 - Scheduling Policies\n",
    "\n",
    " * First-come-first-served (FCFS). I call this FIFO.\n",
    " * Non-preemptive last-come-first-served.\n",
    " * Random - Starts working on a random job from the queue.\n",
    "\n",
    "For fun, let's run the single server with the random queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.80172675871297"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function scheduling_policies()\n",
    "    arrival_rate = 3.0\n",
    "    service_rate = 3.0\n",
    "    model = QueueModel()\n",
    "    source = add_queue!(model, InfiniteSourceQueue())\n",
    "    fifo = add_queue!(model, RandomQueue())\n",
    "    sink = add_queue!(model, SinkQueue())\n",
    "    s1 = add_server!(model, ArrivalServer(arrival_rate))\n",
    "    s2 = add_server!(model, ModifyServer(service_rate))\n",
    "    connect!(model, source, s1, :only)\n",
    "    connect!(model, s1, fifo, :only)\n",
    "    connect!(model, fifo, s2, :only)\n",
    "    connect!(model, s2, sink, :only)\n",
    "    check_model(model)\n",
    "    trajectory = Trajectory(2342334)\n",
    "    start_time = zero(Float64)\n",
    "    activate!(model, trajectory, s1, Work())\n",
    "    when = 0.0\n",
    "    while when < 10000.0\n",
    "        when, which = next(trajectory)\n",
    "        step!(model, trajectory, (when, which))\n",
    "    end\n",
    "    response = sink.retire_total_duration / sink.retire_cnt\n",
    "    return response\n",
    "end\n",
    "scheduling_policies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
